{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1DPGCoztkhRDncXJyNljpE6JWwebdYgN7",
      "authorship_tag": "ABX9TyNAqar8C7lXA1ZUU7AvQdUn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HazelvdW/context-framed-listening/blob/main/framed_listening_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Framed Listening: **BERT analyses**\n",
        "> By **Hazel A. van der Walle** (PhD student, Music, Durham University), October 2025."
      ],
      "metadata": {
        "id": "aWUiV_I4GKz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook mirrors the [Word2Vec analysis](https://github.com/HazelvdW/context-framed-listening/blob/main/framed_listening_Word2Vec.ipynb) and [TF-IDF analysis](https://github.com/HazelvdW/context-framed-listening/blob/main/framed_listening_TFIDF.ipynb) structure for this study.\n",
        "\n",
        "Here, we run the cosine similarity analyses and semantic similarity analyses using Bidirectional Encoder Representations from Transformers (BERT) embeddings.\n",
        "\n",
        "For both of these analyses, two levels of investigation are conducted:\n",
        "1. a broad cateorisation, grouping METs by the genre of the clip (N=4) and context (N=4) pairing (*= 16 documents*)\n",
        "2. grouping METs by specific clip (N=16) and context (N=4) pairing (*= 64 documents*)\n",
        "\n",
        "\n",
        "Overviews are described at the start of each analysis section, and Summaries at the end listing the file outputs.\n",
        "\n"
      ],
      "metadata": {
        "id": "zrMvTrI0tgWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT analysis briefing\n",
        "\n",
        "This code will be answering questions such as \"Do people describe Jazz differently in BAR vs CONCERT contexts?\" and \"Is genre or context more important for similarity?\"\n",
        "\n",
        "* Document-level analysis\n",
        "  * Creates one embedding per document (each genre-context or clip-context combination)\n",
        "  * Builds a full similarity matrix between all documents\n",
        "  * Extracts specific conditions from that matrix\n",
        "* BERT embeddings\n",
        "  * Uses mean pooling across all token embeddings for better document representation\n",
        "  * Handles text truncation with 512 token limit\n",
        "  * Processes each document individually for clean embeddings"
      ],
      "metadata": {
        "id": "Q7KARqggc92k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "All datasets generated and used for this study are openly available on GitHub https://github.com/HazelvdW/context-framed-listening."
      ],
      "metadata": {
        "id": "GnDfhI3ibc2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r context-framed-listening\n",
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/HazelvdW/context-framed-listening.git"
      ],
      "metadata": {
        "id": "fhxKgDlzbc20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refresh files to see **\"context-framed-listening\"**.\n"
      ],
      "metadata": {
        "id": "NXwN17zsbc20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Setup"
      ],
      "metadata": {
        "id": "MvLpIyQxZVAo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH7jpM6PFif6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialise pretrained BERT model and tokeniser (_only need to do this once for this notebook_):"
      ],
      "metadata": {
        "id": "inNO9nJgefPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLoading BERT model and tokeniser...\")\n",
        "BERTtokeniser = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "BERTmodel = BertModel.from_pretrained('bert-base-uncased')\n",
        "print(\"BERT model loaded successfully!\\n\")\n",
        "\n",
        "# Function to get BERT embeddings for text\n",
        "def get_bert_embedding(text):\n",
        "    \"\"\"Get BERT embedding for a single text document.\"\"\"\n",
        "    # Tokenise and encode the text\n",
        "    inputs = BERTtokeniser(text, return_tensors='pt', padding=True,\n",
        "                           truncation=True, max_length=512)\n",
        "\n",
        "    # Get BERT outputs\n",
        "    with torch.no_grad():\n",
        "        outputs = BERTmodel(**inputs)\n",
        "\n",
        "    # Use mean pooling of last hidden states as document embedding\n",
        "    # Shape: (1, hidden_size) -> we take mean across all tokens\n",
        "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "hQsJDP_nee78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load in the data file \"**dataMET_preprocessed.csv**\" that contains the preprocessed text data of participants' thought desciptions, generated using the code notebook titled [framed_listening_text_prep](https://github.com/HazelvdW/context-framed-listening/blob/main/framed_listening_text_prep.ipynb)"
      ],
      "metadata": {
        "id": "-QKT_dIYbc20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataMETpre = pd.read_csv(\"/content/context-framed-listening/NLP_outputs/dataMET_preprocessed.csv\")"
      ],
      "metadata": {
        "id": "ry-tBRXlbc20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Cosine Similarity Analyses\n",
        "\n",
        "**Version 1 (Genre-Context):**\n",
        "\n",
        "* Groups by genre and context (broader categorisation)\n",
        "* Produces 16 document combinations (4 genres × 4 contexts)\n",
        "\n",
        "\n",
        "**Version 2 (Clip-Context):**\n",
        "\n",
        "* Groups by specific clip and context pairing\n",
        "* Produces 64 document combinations (16 clips × 4 contexts)\n",
        "\n",
        "**OUTPUTS:**\n",
        "\n",
        "* Cosine similarity value matrices\n",
        "* Heatmap of cosine similarity values\n"
      ],
      "metadata": {
        "id": "jklv1mgXOYKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "====================================\n",
        "### Version 1: Genre-Context Cosine Matrix\n",
        "===================================="
      ],
      "metadata": {
        "id": "o92FvQ1JeR-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the preprocessed MET descriptions from `dataMETpre` into \"METdocs\".\n"
      ],
      "metadata": {
        "id": "DtwlFRcmjTNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise DataFrame for Version 1\n",
        "METdocs_v1 = pd.DataFrame(index=range(0,1), columns=dataMETpre.columns)\n",
        "rowIndex = 0\n",
        "\n",
        "# Iterate through each unique context word and genre\n",
        "for idContext in np.unique(dataMETpre['context_word']):\n",
        "    for idGenre in np.unique(dataMETpre['clip_genre']):\n",
        "        # Create masks to filter data\n",
        "        contextMask = dataMETpre['context_word'] == idContext\n",
        "        genreMask = dataMETpre['clip_genre'] == idGenre\n",
        "\n",
        "        # Combined mask\n",
        "        mask = [all(tup) for tup in zip(contextMask, genreMask)]\n",
        "        filt_ContextGenreData = dataMETpre[mask]\n",
        "\n",
        "        # Concatenate all text descriptions\n",
        "        descrSeries = filt_ContextGenreData['preprocessed_METdescr']\n",
        "\n",
        "        # Join descriptions with marker\n",
        "        joinedstring = \"\"\n",
        "        for ival in range(0, len(descrSeries.values)):\n",
        "            joinedstring = joinedstring + str(descrSeries.values[ival]) + \" endofasubhere \"\n",
        "\n",
        "        # Assign values to dataframe\n",
        "        METdocs_v1.loc[rowIndex, 'preprocessed_METdescr'] = joinedstring\n",
        "        METdocs_v1.loc[rowIndex, 'idGenreContext'] = idContext[0:3] + \"_\" + idGenre[0:3]\n",
        "\n",
        "        # Assign context code\n",
        "        if idContext[0:3] == 'bar':\n",
        "            METdocs_v1.loc[rowIndex, 'context_code'] = 'BAR'\n",
        "        elif idContext[0:3] == 'con':\n",
        "            METdocs_v1.loc[rowIndex, 'context_code'] = 'CON'\n",
        "        elif idContext[0:3] == 'mov':\n",
        "            METdocs_v1.loc[rowIndex, 'context_code'] = 'MOV'\n",
        "        elif idContext[0:3] == 'vid':\n",
        "            METdocs_v1.loc[rowIndex, 'context_code'] = 'VID'\n",
        "\n",
        "        # Assign genre code\n",
        "        if idGenre[0:3] == '80s':\n",
        "            METdocs_v1.loc[rowIndex, 'genre_code'] = '80s'\n",
        "        elif idGenre[0:3] == 'Jaz':\n",
        "            METdocs_v1.loc[rowIndex, 'genre_code'] = 'Jaz'\n",
        "        elif idGenre[0:3] == 'Met':\n",
        "            METdocs_v1.loc[rowIndex, 'genre_code'] = 'Met'\n",
        "        elif idGenre[0:3] == 'Ele':\n",
        "            METdocs_v1.loc[rowIndex, 'genre_code'] = 'Ele'\n",
        "\n",
        "        rowIndex = rowIndex + 1\n",
        "\n",
        "# Filter and save Version 1\n",
        "METdocs_v1 = METdocs_v1.filter(['context_code', 'genre_code', 'preprocessed_METdescr', 'idGenreContext'], axis=1)\n",
        "METdocs_v1.to_csv('/content/context-framed-listening/NLP_outputs/BERT/METdocs_v1_GenreContext.csv', encoding='utf-8')\n",
        "\n",
        "print(f\"Version 1: Created {len(METdocs_v1)} documents (Genre-Context combinations)\")\n",
        "display(METdocs_v1.head(5))\n"
      ],
      "metadata": {
        "id": "KRM4eZX7tWMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute cosine similarity for version 1:"
      ],
      "metadata": {
        "id": "PUdAFZkrtsw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the METdocs data for Version 1\n",
        "wordsin_v1 = METdocs_v1.copy()\n",
        "\n",
        "# Compute BERT embeddings for each document\n",
        "print(\"Computing BERT embeddings for Version 1 documents...\")\n",
        "bert_embeddings_v1 = []\n",
        "\n",
        "for idx, row in wordsin_v1.iterrows():\n",
        "    text = str(row['preprocessed_METdescr'])\n",
        "    embedding = get_bert_embedding(text)\n",
        "    bert_embeddings_v1.append(embedding)\n",
        "\n",
        "    if (idx + 1) % 5 == 0:\n",
        "        print(f\"  Processed {idx + 1}/{len(wordsin_v1)} documents...\")\n",
        "\n",
        "bert_embeddings_v1 = np.array(bert_embeddings_v1)\n",
        "print(f\"Version 1: BERT embeddings shape: {bert_embeddings_v1.shape}\")\n",
        "\n",
        "# Calculate cosine similarity matrix\n",
        "print(\"Computing cosine similarity matrix for Version 1...\")\n",
        "cosineMatrix_BERT_v1 = cosine_similarity(bert_embeddings_v1, bert_embeddings_v1)\n",
        "\n",
        "# Create labeled DataFrame\n",
        "cosineMatrix_BERT_v1_df = pd.DataFrame(\n",
        "    cosineMatrix_BERT_v1,\n",
        "    index=wordsin_v1['idGenreContext'],\n",
        "    columns=wordsin_v1['idGenreContext']\n",
        ")\n",
        "\n",
        "# Save cosine similarity matrix\n",
        "cosineMatrix_BERT_v1_df.to_csv('/content/context-framed-listening/NLP_outputs/BERT/cosineMatrix_BERT_v1_GenreContext.csv', encoding='utf-8')\n",
        "\n",
        "print(\"\\nVersion 1 BERT Cosine Similarity Matrix:\")\n",
        "display(cosineMatrix_BERT_v1_df)"
      ],
      "metadata": {
        "id": "yk8Kvmn1tzsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "====================================\n",
        "### Version 2: Clip-Context Cosine Matrix\n",
        "===================================="
      ],
      "metadata": {
        "id": "eLOkmYrMuFx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine the preprocessed MET descriptions from `dataMETpre` into \"METdocs\"."
      ],
      "metadata": {
        "id": "rjpJIOqrjZKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise DataFrame for Version 2\n",
        "METdocs_v2 = pd.DataFrame(index=range(0,1), columns=dataMETpre.columns)\n",
        "rowIndex = 0\n",
        "\n",
        "# Iterate through each unique clip_context_PAIR\n",
        "for idStimPair in np.unique(dataMETpre['clip_context_PAIR']):\n",
        "    # Create mask for current stimulus pair\n",
        "    stimPairMask = dataMETpre['clip_context_PAIR'] == idStimPair\n",
        "    filt_ClipContextData = dataMETpre[stimPairMask]\n",
        "\n",
        "    # Get the first row to extract clip and context info\n",
        "    if len(filt_ClipContextData) > 0:\n",
        "        first_row = filt_ClipContextData.iloc[0]\n",
        "        idClip = first_row['clip_name']\n",
        "        idContext = first_row['context_word']\n",
        "\n",
        "        # Concatenate all text descriptions\n",
        "        descrSeries = filt_ClipContextData['preprocessed_METdescr']\n",
        "\n",
        "        joinedstring = \"\"\n",
        "        for ival in range(0, len(descrSeries.values)):\n",
        "            joinedstring = joinedstring + str(descrSeries.values[ival]) + \" endofasubhere \"\n",
        "\n",
        "        # Assign values to dataframe\n",
        "        METdocs_v2.loc[rowIndex, 'preprocessed_METdescr'] = joinedstring\n",
        "        METdocs_v2.loc[rowIndex, 'clip_name'] = idClip\n",
        "        METdocs_v2.loc[rowIndex, 'context_word'] = idContext\n",
        "        METdocs_v2.loc[rowIndex, 'idClipContext'] = idStimPair\n",
        "        METdocs_v2.loc[rowIndex, 'idGenreContext'] = idStimPair[0:3] + \"_\" + idClip[0:3]\n",
        "\n",
        "        # Assign genre code\n",
        "        if idClip[0:3] == '80s':\n",
        "            METdocs_v2.loc[rowIndex, 'genre_code'] = '80s'\n",
        "        elif idClip[0:3] == 'Jaz':\n",
        "            METdocs_v2.loc[rowIndex, 'genre_code'] = 'Jaz'\n",
        "        elif idClip[0:3] == 'Met':\n",
        "            METdocs_v2.loc[rowIndex, 'genre_code'] = 'Met'\n",
        "        elif idClip[0:3] == 'Ele':\n",
        "            METdocs_v2.loc[rowIndex, 'genre_code'] = 'Ele'\n",
        "\n",
        "        rowIndex = rowIndex + 1\n",
        "\n",
        "# Filter and save Version 2\n",
        "METdocs_v2 = METdocs_v2.filter(['context_word', 'genre_code', 'clip_name', 'preprocessed_METdescr', 'idClipContext', 'idGenreContext'], axis=1)\n",
        "METdocs_v2.to_csv('/content/context-framed-listening/NLP_outputs/BERT/METdocs_v2_ClipContext.csv', encoding='utf-8')\n",
        "\n",
        "print(f\"Version 2: Created {len(METdocs_v2)} documents (Clip-Context combinations)\")\n",
        "display(METdocs_v2.head(5))"
      ],
      "metadata": {
        "id": "2ZvbeNkxtWJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute cosine similarity for Version 2:"
      ],
      "metadata": {
        "id": "R4AJHiGouNLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the METdocs data for Version 2\n",
        "wordsin_v2 = METdocs_v2.copy()\n",
        "\n",
        "# Compute BERT embeddings for each document\n",
        "print(\"Computing BERT embeddings for Version 2 documents...\")\n",
        "bert_embeddings_v2 = []\n",
        "\n",
        "for idx, row in wordsin_v2.iterrows():\n",
        "    text = str(row['preprocessed_METdescr'])\n",
        "    embedding = get_bert_embedding(text)\n",
        "    bert_embeddings_v2.append(embedding)\n",
        "\n",
        "    if (idx + 1) % 10 == 0:\n",
        "        print(f\"  Processed {idx + 1}/{len(wordsin_v2)} documents...\")\n",
        "\n",
        "bert_embeddings_v2 = np.array(bert_embeddings_v2)\n",
        "print(f\"Version 2: BERT embeddings shape: {bert_embeddings_v2.shape}\")\n",
        "\n",
        "# Calculate cosine similarity matrix\n",
        "print(\"Computing cosine similarity matrix for Version 2...\")\n",
        "cosineMatrix_BERT_v2 = cosine_similarity(bert_embeddings_v2, bert_embeddings_v2)\n",
        "\n",
        "# Create labeled DataFrame\n",
        "cosineMatrix_BERT_v2_df = pd.DataFrame(\n",
        "    cosineMatrix_BERT_v2,\n",
        "    index=wordsin_v2['idClipContext'],\n",
        "    columns=wordsin_v2['idClipContext']\n",
        ")\n",
        "\n",
        "# Save cosine similarity matrix\n",
        "cosineMatrix_BERT_v2_df.to_csv('/content/context-framed-listening/NLP_outputs/BERT/cosineMatrix_BERT_v2_ClipContext.csv', encoding='utf-8')\n",
        "\n",
        "print(\"\\nVersion 2 BERT Cosine Similarity Matrix:\")\n",
        "display(cosineMatrix_BERT_v2_df)"
      ],
      "metadata": {
        "id": "ICeBLgt7tWFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "====================================\n",
        "#### VISUALISATIONS: Cosine Matrix\n",
        "===================================="
      ],
      "metadata": {
        "id": "_OPM9f1iuXGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation for Version 1\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cosineMatrix_BERT_v1_df, cmap='viridis', annot=False)\n",
        "plt.title('Version 1: BERT Cosine Similarity Matrix (Genre-Context)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/context-framed-listening/NLP_outputs/BERT/heatmap_BERT_v1_GenreContext.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Visualisation for Version 2\n",
        "plt.figure(figsize=(14, 12))\n",
        "sns.heatmap(cosineMatrix_BERT_v2_df, cmap='viridis', annot=False)\n",
        "plt.title('Version 2: BERT Cosine Similarity Matrix (Clip-Context)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/context-framed-listening/NLP_outputs/BERT/heatmap_BERT_v2_ClipContext.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g21-5DpOuUmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SUMMARY"
      ],
      "metadata": {
        "id": "KX_ZvJPuzrha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nOutput files created:\")\n",
        "print(\"  - cosineMatrix_BERT_v1_GenreContext.csv\")\n",
        "print(\"  - heatmap_BERT_v1_GenreContext.png\")\n",
        "print(\"  - cosineMatrix_BERT_v2_ClipContext.csv\")\n",
        "print(\"  - heatmap_BERT_v2_ClipContext.png\")"
      ],
      "metadata": {
        "id": "91sqqC8Azs0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Semantic Similarity Analyses\n",
        "\n",
        "**OUTPUTS:**\n",
        "\n",
        "All Representational Dissimilarity Matrix (RDM) masks and similarity measures are saved separately for each version, ready for statistical analysis in R.\n",
        "\n",
        "=== *ANALYSIS STRUCTURE* ===\n",
        "\n",
        "\n",
        "**Version 1 (Genre-Context) - 5 conditions:**\n",
        "\n",
        "* Same context, different genre\n",
        "* Different context, same genre\n",
        "* Different context, different genre\n",
        "* Between (dif.) contexts\n",
        "* Between (dif.) genres\n",
        "\n",
        "\n",
        "**Version 2 (Clip-Context) - 7 conditions:**\n",
        "\n",
        "* Same context, different clip\n",
        "* Different context, same clip\n",
        "* Different context, different clip\n",
        "* Between (dif.) contexts\n",
        "* Between (dif.) clips\n",
        "* Within (same) genre\n",
        "* Between (dif.) genres\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6pP5Bayv2Cx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "====================================\n",
        "### Version 1: Genre-Context Semantic Similarity\n",
        "===================================="
      ],
      "metadata": {
        "id": "i1CprYn2yPJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up label columns, NumPy arrays, and stimuli condition masks:"
      ],
      "metadata": {
        "id": "wYGsKpFHywil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inData_bert_v1 = METdocs_v1\n",
        "simData_bert_v1 = cosineMatrix_BERT_v1_df\n",
        "\n",
        "# Extract label columns\n",
        "labelsCG_bert_v1 = inData_bert_v1['idGenreContext']\n",
        "labelsGenre_bert_v1 = inData_bert_v1['genre_code']\n",
        "labelsContext_bert_v1 = inData_bert_v1['context_code']\n",
        "\n",
        "# Initialise arrays - 8 conditions\n",
        "sContext_dGenre_bert_v1 = np.zeros(shape=(len(labelsCG_bert_v1), len(labelsCG_bert_v1)))\n",
        "dContext_sGenre_bert_v1 = np.zeros(shape=(len(labelsCG_bert_v1), len(labelsCG_bert_v1)))\n",
        "dContext_dGenre_bert_v1 = np.zeros(shape=(len(labelsCG_bert_v1), len(labelsCG_bert_v1)))\n",
        "bwContext_bert_v1 = np.zeros(shape=(len(labelsCG_bert_v1), len(labelsCG_bert_v1)))\n",
        "bwGenre_bert_v1 = np.zeros(shape=(len(labelsCG_bert_v1), len(labelsCG_bert_v1)))\n",
        "\n",
        "# Build condition masks\n",
        "for irow in range(0, len(labelsCG_bert_v1.values)):\n",
        "    for icol in range(0, irow):\n",
        "        same_context = labelsContext_bert_v1.values[irow] == labelsContext_bert_v1.values[icol]\n",
        "        same_genre = labelsGenre_bert_v1.values[irow] == labelsGenre_bert_v1.values[icol]\n",
        "\n",
        "        # Stimuli combinatorial conditions\n",
        "        if same_context and not same_genre:\n",
        "            sContext_dGenre_bert_v1[irow, icol] = 1\n",
        "        elif not same_context and same_genre:\n",
        "            dContext_sGenre_bert_v1[irow, icol] = 1\n",
        "        elif not same_context and not same_genre:\n",
        "            dContext_dGenre_bert_v1[irow, icol] = 1\n",
        "\n",
        "        # Between context\n",
        "        if not same_context:\n",
        "            bwContext_bert_v1[irow, icol] = 1\n",
        "\n",
        "        # Between genre\n",
        "        if not same_genre:\n",
        "            bwGenre_bert_v1[irow, icol] = 1"
      ],
      "metadata": {
        "id": "NzmBZM4oyLt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract similarity values for each condition:"
      ],
      "metadata": {
        "id": "zj1z_EqYyoRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simMeasures_bert_v1 = {'type': [], 'sim': []}\n",
        "\n",
        "conditions_bert_v1 = {\n",
        "    'sContext_dGenre': sContext_dGenre_bert_v1,\n",
        "    'dContext_sGenre': dContext_sGenre_bert_v1,\n",
        "    'dContext_dGenre': dContext_dGenre_bert_v1,\n",
        "    'bwContext': bwContext_bert_v1,\n",
        "    'bwGenre': bwGenre_bert_v1\n",
        "}\n",
        "\n",
        "for condition_name, condition_mask in conditions_bert_v1.items():\n",
        "    simVals = simData_bert_v1.values[condition_mask == 1]\n",
        "    for val in simVals:\n",
        "        simMeasures_bert_v1['type'].append(condition_name)\n",
        "        simMeasures_bert_v1['sim'].append(val)\n",
        "\n",
        "# Create DataFrame\n",
        "simMeasuresDF_bert_v1 = pd.DataFrame(data=simMeasures_bert_v1)\n",
        "simMeasuresDF_bert_v1 = simMeasuresDF_bert_v1.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "print(f\"\\nVersion 1 BERT Similarity Measures extracted (8 conditions):\")\n",
        "print(simMeasuresDF_bert_v1.groupby('type').agg({'sim': ['count', 'mean', 'std']}))\n",
        "\n",
        "# Save outputs\n",
        "simMeasuresDF_bert_v1.to_csv('/content/context-framed-listening/NLP_outputs/BERT/simMeasuresDF_BERT_v1_GenreContext.csv', encoding='utf-8', index=False)\n",
        "pd.DataFrame(sContext_dGenre_bert_v1).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_sContext_dGenre_BERT_v1.csv', encoding='utf-8')\n",
        "pd.DataFrame(dContext_sGenre_bert_v1).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_dContext_sGenre_BERT_v1.csv', encoding='utf-8')\n",
        "pd.DataFrame(dContext_dGenre_bert_v1).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_dContext_dGenre_BERT_v1.csv', encoding='utf-8')\n",
        "pd.DataFrame(bwContext_bert_v1).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_bwContext_BERT_v1.csv', encoding='utf-8')\n",
        "pd.DataFrame(bwGenre_bert_v1).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_bwGenre_BERT_v1.csv', encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "qtABOOHjyLq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "====================================\n",
        "### Version 2: Clip-Context Semantic Similarity\n",
        "===================================="
      ],
      "metadata": {
        "id": "7ltgh_r-zEsL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up label columns, NumPy arrays, and stimuli condition masks:"
      ],
      "metadata": {
        "id": "NfTnUVzDzEsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inData_bert_v2 = METdocs_v2\n",
        "simData_bert_v2 = cosineMatrix_BERT_v2_df\n",
        "\n",
        "# Extract label columns\n",
        "labelsCG_bert_v2 = inData_bert_v2['idClipContext']\n",
        "labelsClip_bert_v2 = inData_bert_v2['clip_name']\n",
        "labelsGenre_bert_v2 = inData_bert_v2['genre_code']\n",
        "labelsContext_bert_v2 = inData_bert_v2['context_word']\n",
        "\n",
        "# Initialise arrays\n",
        "sContext_dClip_bert_v2 = np.zeros(shape=(len(labelsCG_bert_v2), len(labelsCG_bert_v2)))\n",
        "dContext_sClip_bert_v2 = np.zeros(shape=(len(labelsCG_bert_v2), len(labelsCG_bert_v2)))\n",
        "dContext_dClip_bert_v2 = np.zeros(shape=(len(labelsCG_bert_v2), len(labelsCG_bert_v2)))\n",
        "bwContext_bert_v2 = np.zeros(shape=(len(labelsCG_bert_v2), len(labelsCG_bert_v2)))\n",
        "bwClip_bert_v2 = np.zeros(shape=(len(labelsCG_bert_v2), len(labelsCG_bert_v2)))\n",
        "bwGenre_bert_v2 = np.zeros(shape=(len(labelsCG_bert_v2), len(labelsCG_bert_v2)))\n",
        "wiGenre_bert_v2 = np.zeros(shape=(len(labelsCG_bert_v2), len(labelsCG_bert_v2)))\n",
        "\n",
        "# Build condition masks\n",
        "for irow in range(0, len(labelsCG_bert_v2.values)):\n",
        "    for icol in range(0, irow):\n",
        "        same_context = labelsContext_bert_v2.values[irow] == labelsContext_bert_v2.values[icol]\n",
        "        same_clip = labelsClip_bert_v2.values[irow] == labelsClip_bert_v2.values[icol]\n",
        "        same_genre = labelsGenre_bert_v2.values[irow] == labelsGenre_bert_v2.values[icol]\n",
        "\n",
        "        # Stimuli combinatorial conditions\n",
        "        if same_context and not same_clip:\n",
        "            sContext_dClip_bert_v2[irow, icol] = 1\n",
        "        elif not same_context and same_clip:\n",
        "            dContext_sClip_bert_v2[irow, icol] = 1\n",
        "        elif not same_context and not same_clip:\n",
        "            dContext_dClip_bert_v2[irow, icol] = 1\n",
        "\n",
        "        # Between context\n",
        "        if same_context:\n",
        "            bwContext_bert_v2[irow, icol] = 1\n",
        "\n",
        "        # Between clip\n",
        "        if same_clip:\n",
        "            bwClip_bert_v2[irow, icol] = 1\n",
        "\n",
        "        # Within/Between genre\n",
        "        if same_genre:\n",
        "            wiGenre_bert_v2[irow, icol] = 1\n",
        "        else:\n",
        "            bwGenre_bert_v2[irow, icol] = 1"
      ],
      "metadata": {
        "id": "zSFBSa_SzEsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract similarity values for each condition:"
      ],
      "metadata": {
        "id": "Q1EvCY6QzEsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simMeasures_bert_v2 = {'type': [], 'sim': []}\n",
        "\n",
        "conditions_bert_v2 = {\n",
        "    'sContext_dClip': sContext_dClip_bert_v2,\n",
        "    'dContext_sClip': dContext_sClip_bert_v2,\n",
        "    'dContext_dClip': dContext_dClip_bert_v2,\n",
        "    'bwContext': bwContext_bert_v2,\n",
        "    'bwClip': bwClip_bert_v2,\n",
        "    'bwGenre': bwGenre_bert_v2,\n",
        "    'wiGenre': wiGenre_bert_v2\n",
        "}\n",
        "\n",
        "for condition_name, condition_mask in conditions_bert_v2.items():\n",
        "    simVals = simData_bert_v2.values[condition_mask == 1]\n",
        "    for val in simVals:\n",
        "        simMeasures_bert_v2['type'].append(condition_name)\n",
        "        simMeasures_bert_v2['sim'].append(val)\n",
        "\n",
        "# Create DataFrame\n",
        "simMeasuresDF_bert_v2 = pd.DataFrame(data=simMeasures_bert_v2)\n",
        "simMeasuresDF_bert_v2 = simMeasuresDF_bert_v2.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "print(f\"\\nVersion 2 BERT Similarity Measures extracted (10 conditions):\")\n",
        "print(simMeasuresDF_bert_v2.groupby('type').agg({'sim': ['count', 'mean', 'std']}))\n",
        "\n",
        "# Save outputs\n",
        "simMeasuresDF_bert_v2.to_csv('/content/context-framed-listening/NLP_outputs/BERT/simMeasuresDF_BERT_v2_ClipContext.csv', encoding='utf-8', index=False)\n",
        "pd.DataFrame(sContext_dClip_bert_v2).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_sContext_dClip_BERT_v2.csv', encoding='utf-8')\n",
        "pd.DataFrame(dContext_sClip_bert_v2).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_dContext_sClip_BERT_v2.csv', encoding='utf-8')\n",
        "pd.DataFrame(dContext_dClip_bert_v2).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_dContext_dClip_BERT_v2.csv', encoding='utf-8')\n",
        "pd.DataFrame(bwContext_bert_v2).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_bwContext_BERT_v2.csv', encoding='utf-8')\n",
        "pd.DataFrame(bwClip_bert_v2).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_bwClip_BERT_v2.csv', encoding='utf-8')\n",
        "pd.DataFrame(bwGenre_bert_v2).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_bwGenre_BERT_v2.csv', encoding='utf-8')\n",
        "pd.DataFrame(wiGenre_bert_v2).to_csv('/content/context-framed-listening/NLP_outputs/BERT/RDM_wiGenre_BERT_v2.csv', encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "aqVnht-PzEsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "====================================\n",
        "#### VISUALISATIONS for BERT analyses\n",
        "====================================\n",
        "\n",
        "* Box plots\n",
        "* Violin plots\n",
        "* Bar plots"
      ],
      "metadata": {
        "id": "SJLbBycU2V-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plots comparing conditions - Version 1\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
        "simMeasuresDF_bert_v1.boxplot(column='sim', by='type', ax=ax, rot=45)\n",
        "ax.set_title('Version 1: BERT Similarity Distributions (Genre-Context)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Condition Type', fontsize=12)\n",
        "ax.set_ylabel('BERT Cosine Similarity', fontsize=12)\n",
        "plt.suptitle('')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/context-framed-listening/NLP_outputs/BERT/similarity_boxplot_BERT_v1_GenreContext.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Box plots comparing conditions - Version 2\n",
        "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
        "simMeasuresDF_bert_v2.boxplot(column='sim', by='type', ax=ax, rot=45)\n",
        "ax.set_title('Version 2: BERT Similarity Distributions (Clip-Context)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Condition Type', fontsize=12)\n",
        "ax.set_ylabel('BERT Cosine Similarity', fontsize=12)\n",
        "plt.suptitle('')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/context-framed-listening/NLP_outputs/BERT/similarity_boxplot_BERT_v2_ClipContext.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Violin plot comparing conditions - Version 1\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
        "sns.violinplot(data=simMeasuresDF_BERT_v1, x='type', y='sim', hue='type', ax=ax, palette='Set2', legend=False)\n",
        "ax.set_title('Version 1: Similarity Distributions by Condition (Genre-Context)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Condition Type', fontsize=12)\n",
        "ax.set_ylabel('Cosine Similarity', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/context-framed-listening/NLP_outputs/BERT/similarity_violin_BERT_v1_GenreContext.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Violin plot comparing conditions - Version 2\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
        "sns.violinplot(data=simMeasuresDF_BERT_v2, x='type', y='sim', hue='type', ax=ax, palette='Set2', legend=False)\n",
        "ax.set_title('Version 2: Similarity Distributions by Condition (Genre-Context)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Condition Type', fontsize=12)\n",
        "ax.set_ylabel('Cosine Similarity', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/context-framed-listening/NLP_outputs/BERT/similarity_violin_BERT_v2_GenreContext.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Bar plots with means - Version 1\n",
        "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
        "means_bert_v1 = simMeasuresDF_bert_v1.groupby('type')['sim'].mean().sort_values(ascending=False)\n",
        "stds_bert_v1 = simMeasuresDF_bert_v1.groupby('type')['sim'].std()\n",
        "means_bert_v1.plot(kind='bar', ax=ax, yerr=stds_bert_v1, capsize=4, color='steelblue', edgecolor='black', alpha=0.8)\n",
        "ax.set_title('Version 1: Mean BERT Similarity by Condition (Genre-Context)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Condition Type', fontsize=12)\n",
        "ax.set_ylabel('Mean BERT Cosine Similarity', fontsize=12)\n",
        "ax.set_xticklabels(means_bert_v1.index, rotation=45, ha='right')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/context-framed-listening/NLP_outputs/BERT/similarity_means_BERT_v1_GenreContext.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Bar plots with means - Version 2\n",
        "fig, ax = plt.subplots(1, 1, figsize=(14, 6))\n",
        "means_bert_v2 = simMeasuresDF_bert_v2.groupby('type')['sim'].mean().sort_values(ascending=False)\n",
        "stds_bert_v2 = simMeasuresDF_bert_v2.groupby('type')['sim'].std()\n",
        "means_bert_v2.plot(kind='bar', ax=ax, yerr=stds_bert_v2, capsize=4, color='coral', edgecolor='black', alpha=0.8)\n",
        "ax.set_title('Version 2: Mean BERT Similarity by Condition (Clip-Context)', fontsize=14, fontweight='bold')\n",
        "ax.set_xlabel('Condition Type', fontsize=12)\n",
        "ax.set_ylabel('Mean BERT Cosine Similarity', fontsize=12)\n",
        "ax.set_xticklabels(means_bert_v2.index, rotation=45, ha='right')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/context-framed-listening/NLP_outputs/BERT/similarity_means_BERT_v2_ClipContext.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OV0slC6P2DAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SUMMARY"
      ],
      "metadata": {
        "id": "MRj8lwSIzU7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nVersion 1 (Genre-Context) BERT Output Files:\")\n",
        "print(\"  Data Files:\")\n",
        "print(\"    - cosineMatrix_BERT_v1_GenreContext.csv\")\n",
        "print(\"    - simMeasuresDF_BERT_v1_GenreContext.csv\")\n",
        "print(\"    - RDM masks (8 CSV files)\")\n",
        "print(\"  Visualizations:\")\n",
        "print(\"    - heatmap_BERT_v1_GenreContext.png\")\n",
        "print(\"    - similarity_boxplot_BERT_v1_GenreContext.png\")\n",
        "print(\"    - similarity_violin_BERT_v1_GenreContext.png\")\n",
        "print(\"    - similarity_means_BERT_v1_GenreContext.png\")\n",
        "print(\"\\nVersion 2 (Clip-Context) BERT Output Files:\")\n",
        "print(\"  Data Files:\")\n",
        "print(\"    - cosineMatrix_BERT_v2_ClipContext.csv\")\n",
        "print(\"    - simMeasuresDF_BERT_v2_ClipContext.csv\")\n",
        "print(\"    - RDM masks (10 CSV files)\")\n",
        "print(\"  Visualizations:\")\n",
        "print(\"    - heatmap_BERT_v2_ClipContext.png\")\n",
        "print(\"    - similarity_boxplot_BERT_v2_ClipContext.png\")\n",
        "print(\"    - similarity_violin_BERT_v2_GenreContext.png\")\n",
        "print(\"    - similarity_means_BERT_v2_ClipContext.png\")"
      ],
      "metadata": {
        "id": "HLVkMccmyLm3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}